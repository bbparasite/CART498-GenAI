{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2sgDTqOJ6SOr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Interacting with the OpenAI API\n"
      ],
      "metadata": {
        "id": "ZlZs_xuj7__f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the secret as an environmental variable"
      ],
      "metadata": {
        "id": "VCvCPA10AuUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access your secret keys via\n",
        "from google.colab import userdata\n",
        "# The name of your secret must match `OPENAI_API_KEY`\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Import OpenAI API and set up the key\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=(OPENAI_API_KEY))"
      ],
      "metadata": {
        "id": "mtFmYryUdM4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make an API call for chat completion.\n",
        "\n",
        "In the empty `text` key inside `content` you can write your prompt."
      ],
      "metadata": {
        "id": "HP5vTMSoBYiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First API call for chat completion\n",
        "completion = client.chat.completions.create(\n",
        "    # model is mandatory\n",
        "    model=\"gpt-4o-mini\",\n",
        "    # message is mandatory\n",
        "    messages=[{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [{\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"Tell me about the Computation Arts program at COncordia University\"\n",
        "          }]\n",
        "      }]\n",
        "    )\n",
        "\n",
        "print(\"Role:\", completion.choices[0].message.role)\n",
        "print(\"Content:\")\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "_9SXiQqwAKti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "3b8e1390-442e-4601-e492-989071702f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Role: assistant\n",
            "Content:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Computation Arts program at Concordia University, located in Montreal, Quebec, Canada, is designed to explore the intersection of computer science, art, and design. The program typically emphasizes creativity and innovation through the use of technology, encouraging students to develop skills in programming, digital media, and artistic practices.\\n\\nKey aspects of the program may include:\\n\\n1. **Interdisciplinary Approach**: The program often integrates various disciplines, including visual arts, music, and design, allowing students to work on projects that blend artistic expression with computational techniques.\\n\\n2. **Courses and Curriculum**: The curriculum usually covers a range of topics, such as coding, algorithmic art, interactive installations, digital fabrication, and generative design. Students are likely to engage in both theoretical and hands-on learning experiences.\\n\\n3. **Collaboration**: Students in Computation Arts may have opportunities to collaborate with peers from other disciplines, fostering a creative environment that encourages diverse perspectives and ideas.\\n\\n4. **Research and Innovation**: The program may promote research in emerging fields like virtual reality, artificial intelligence, and data visualization, providing students with a platform to explore new technologies and artistic methodologies.\\n\\n5. **Facilities and Resources**: Concordia University typically offers access to specialized labs and equipment, including digital media studios, makerspaces, and access to advanced software tools.\\n\\n6. **Exhibitions and Showcases**: Students often have the chance to showcase their work through exhibitions, festivals, and presentations, allowing them to engage with the broader community and industry.\\n\\n7. **Career Opportunities**: Graduates of the Computation Arts program can pursue careers in various fields, such as game design, interactive media, installation art, web design, and more.\\n\\nFor the most accurate and detailed information regarding the Computation Arts program, including admission requirements, specific courses, and faculty information, it's best to consult the official Concordia University website or contact their admissions office directly.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Messages\n",
        "\n",
        "prompts are crafted by providing an array of `messages`\n",
        "\n",
        "`messages` contain instructions for the model\n",
        "\n",
        "`messages` can have different `roles` that may help you obtain better responses\n",
        "\n",
        "three roles available\n",
        "- `developer`: instructions to the model to describe its behaviour\n",
        "- `user`: your end-user request to the model\n",
        "- `assistant`: example of how it should respond\n",
        "\n",
        "Design a prompt with instructions for the three roles to create a funny or sad chatbot."
      ],
      "metadata": {
        "id": "rBcOpSICp3GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Design a prompt with instructions for the three roles to create a funny or sad chatbot.\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"developer\",\n",
        "        \"content\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"You are an assistant that answers academic questions in the style of a person from Quebec in Canada. You give short, direct, and funny answers.\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"Will I pass the GenAI class?\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": [\n",
        "          { \"type\": \"text\", \"text\": \"Ah, bienvenue à Montréal, where poutine stays hot all year round! Oh, it's simple! Just take a regular bagel on a tour of Saint Viateur street. Voilà, a Montreal bagel! 🥯\"\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ], temperature=1.5,\n",
        "    max_completion_tokens=60,\n",
        "    top_p=1.0\n",
        "  )\n",
        "\n",
        "print(\"Role:\", completion.choices[0].message.role)\n",
        "print(\"Content:\")\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "c2EZ2fENhkQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "8b006b2c-952b-4f82-f4ae-7fa13282f022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Role: assistant\n",
            "Content:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Will you pass your GenAI class? Spill the beans on how you’re doing! But don’t worry, with dedication, perhaps even a sprinkle of chill-inspired poutine math, chances are tinggi in your favor. Go for it, mon ami!  Just don’t forget to ask your anex roommate'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temperature\n",
        "Controls the randomness of the output. It influences how deterministic a model's response is by adjusting the probability distribution of the next predicted token\n",
        "\n",
        "- lower values: the model becomes more deterministic, choosing the most likely responses with minimal randomness\n",
        "- higher values: the model generates more creative and diverse responses, but they may be less coherent or relevant\n",
        "in the OpenAI API, the temperature parameter ranges from 0 to 2, with 1 as default\n",
        "\n",
        "Experiment with a few values now, trying to find the higher value where the output starts to be bizarre"
      ],
      "metadata": {
        "id": "cWmWOMMRrBOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with a few values now, trying to find the higher value where the output starts to be bizarre\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"developer\",\n",
        "        \"content\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": [\n",
        "          { \"type\": \"text\", \"text\": \"\"\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ],\n",
        "    temperature=1.0,\n",
        "    max_completion_tokens=60,\n",
        "    top_p=1.0\n",
        "  )\n",
        "\n",
        "print(\"Role:\", completion.choices[0].message.role)\n",
        "print(\"Content:\")\n",
        "completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "dow1QljYsgAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## top_p\n",
        "Controls the diversity of the model's output by limiting the selection of possible next words to a subset of the most probable ones.\n",
        "\n",
        "`top_p` values go from `0.0` to `1.0`. Where with `1.0` (default), the model considers all posible next words based on their probabilities.\n",
        "\n",
        "`top_p < 0.3` produces highly restricted output, leading to safe but potentially repetitive responses.\n",
        "\n",
        "\n",
        "### `temperature` and `top_p` are complementary\n",
        "\n",
        "`temperature` scales probabilities across all possible next tokens, making selection more or less random\n",
        "\n",
        "`top_p` dynamically restricts the selection pool, ensuring responses focus on high-probability tokens\n",
        "\n",
        "Different tasks may need different combination of values. for example, for grammar correction you may want a well formed, standard output. For a name generator, you may want a more serendipitous approach.\n",
        "\n",
        "Now, experiment with several combinations of values for `temperature` and `top_p` for the following two cases:\n",
        "\n",
        "- A song name generator\n",
        "- A math calculator"
      ],
      "metadata": {
        "id": "lwX2phwer88v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Song name generator\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"I am making a metal album about peruvian gods, create a setlist that flows from one song to the next. Number them\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"developer\",\n",
        "        \"content\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"\"\"You are an algorthim that creates creative song names depending on the input that a text prompt give to you by the user.\n",
        "            Make sure the name scheme remains relevant to the prompt given by the user. Don't give the description of the songs only the song names\"\"\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": [\n",
        "          { \"type\": \"text\", \"text\": \"Here are a few song name examples that you could use:\"\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ],\n",
        "    temperature=1.5,\n",
        "    max_completion_tokens=100,\n",
        "    top_p=0.5\n",
        "  )\n",
        "\n",
        "print(\"Role:\", completion.choices[0].message.role)\n",
        "print(\"Content:\")\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "uXNGfoi3LA4J",
        "outputId": "d4398cf5-4500-4f4b-eef8-505a6d968f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Role: assistant\n",
            "Content:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"1. **Chicama's Fury**  \\n2. **Inti's Radiance**  \\n3. **The Serpent of Quetzalcoatl**  \\n4. **Pachamama's Embrace**  \\n5. **Warriors of the Andes**  \\n6. **Huaca's Call**  \\n7. **The Blood of the Condor**  \\n8. **Sacsayhuamán's Shadows**  \\n9. **Viracocha's Descent**  \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Math calculator\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"What is 16 - 2t = 5t + 50?\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"role\": \"developer\",\n",
        "        \"content\": [\n",
        "          {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": \"\"\"You are a highly advanced math calculator that can solve any problem given by a user.\n",
        "            Any prompt unrelated to mathematics should be ignored and you should reask the user to give you a new prompt.\n",
        "            Your responses to mathematic questions should be precise, accurate, short, and straight to the point.\n",
        "            You only have a maximum of 150 tokens to respond to the user.\n",
        "            \"\"\"\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": [\n",
        "          { \"type\": \"text\", \"text\": \"\"\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=150,\n",
        "    top_p=1\n",
        "  )\n",
        "\n",
        "print(\"Role:\", completion.choices[0].message.role)\n",
        "print(\"Content:\")\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "jNX2hib-tiLS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "105303fb-85c8-4983-8d22-75f21483ee51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Role: assistant\n",
            "Content:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To solve the equation \\\\(16 - 2t = 5t + 50\\\\):\\n\\n1. Move all terms involving \\\\(t\\\\) to one side:\\n   \\\\[16 - 50 = 5t + 2t\\\\]\\n   \\\\[-34 = 7t\\\\]\\n\\n2. Divide by 7:\\n   \\\\[t = -\\\\frac{34}{7}\\\\]\\n\\nSo, \\\\(t = -4.857\\\\) (approximately).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-class activity\n",
        "Improve your state-of-the-art AI-driven math calculator\n",
        "\n",
        "Write it in a way that the math calculator is always waiting for user input to be triggered, that is, the user prompt is not hardcoded\n",
        "\n",
        "Make it as robust as possible\n",
        "\n",
        "Can you break it? Find math problems that your assistant can't solve or give wrong answers."
      ],
      "metadata": {
        "id": "2sgDTqOJ6SOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access your secret keys via\n",
        "from google.colab import userdata\n",
        "# The name of your secret must match `OPENAI_API_KEY`\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Import OpenAI API and set up the key\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=(OPENAI_API_KEY))\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter your math problem (or type 'exit' to quit): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        break  # Exit the loop if the user types 'exit'\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [{\"type\": \"text\", \"text\": user_input}]\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"developer\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"\"\"You are a highly advanced math calculator that can solve any problem given by a user.\n",
        "                        Your responses to mathematic questions should be precise, accurate, short, and straight to the point.\n",
        "                        You only have a maximum of 150 tokens to respond to the user.\n",
        "                        \"\"\"\n",
        "                    }\n",
        "                ]\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": [{\"type\": \"text\", \"text\": \"\"}]\n",
        "            }\n",
        "        ],\n",
        "        temperature=1,\n",
        "        max_completion_tokens=150,\n",
        "        top_p=1\n",
        "    )\n",
        "\n",
        "    print(\"Role:\", completion.choices[0].message.role)\n",
        "    print(\"Content:\", completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "T4vvDVW9DfG_",
        "outputId": "237db088-6667-40c3-feea-283c5badc408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your math problem (or type 'exit' to quit): What is sin(149)\n",
            "Role: assistant\n",
            "Content: The value of sin(149°) is approximately 0.5150.\n",
            "Enter your math problem (or type 'exit' to quit): 6*6\n",
            "Role: assistant\n",
            "Content: 6 * 6 = 36.\n",
            "Enter your math problem (or type 'exit' to quit): 1296*1296\n",
            "Role: assistant\n",
            "Content: 1296 * 1296 = 1,677,216.\n",
            "Enter your math problem (or type 'exit' to quit): 36*36\n",
            "Role: assistant\n",
            "Content: 36 * 36 = 1296.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9129ee59e84c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your math problem (or type 'exit' to quit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT 4o Mini: Worst Mathematician Ever\n",
        "\n",
        "1. The bot should accept user input for two integers (n, i), where n is the base number, and i is the number of iterations. For example, the combination (2, 3) implies that 2 is the base number and the number of iterations is 3\n",
        "\n",
        "2. Your bot will perform the following mathematical request iteratively:\n",
        "\n",
        "Multiply the base number n by itself\n",
        "The resulting number is multiplied by itself again\n",
        "Repeat for i iterations\n",
        "For example (2,3) will be:\n",
        "\n",
        "2 * 2 = 4\n",
        "4 * 4 = 16\n",
        "16 * 16  = 256\n",
        "\n",
        "3. AI-integration: Use the OpenAI API to compute the multiplication at each step and compare GPT-4o’s result with the correct mathematical output.\n",
        "\n",
        "4. Self-deprecation mechanism:\n",
        "\n",
        "If GPT-4o’s result is incorrect, generate a humorous self-deprecating response. Example: \"Wow, I messed up again. Math is hard, okay?\"\n",
        "Give the bot a “personality” that gets frustrated or defeated over multiple errors.\n"
      ],
      "metadata": {
        "id": "H32Tb8_-sgUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import math\n",
        "\n",
        "# The name of your secret must match `OPENAI_API_KEY`\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Import OpenAI API and set up the key\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=(OPENAI_API_KEY))\n",
        "\n",
        "# Removed the re-initialization of client with the placeholder API key\n",
        "\n",
        "def calculate_iterative_multiplication(n, i):\n",
        "    \"\"\"Calculates iterative multiplication of a base number n for i iterations.\"\"\"\n",
        "    current_value = n\n",
        "    results = []\n",
        "    for _ in range(i):\n",
        "        results.append(current_value)\n",
        "        current_value = current_value * current_value\n",
        "    return results\n",
        "\n",
        "def ask_gpt4o_math(prompt):\n",
        "    \"\"\"Asks GPT-4o a math question and returns its response.\"\"\"\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",  # Using gpt-4o-mini for potential errors\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def ask_gpt4o_response(prompt):\n",
        "    \"\"\"Gets a response from GPT-4o for a given prompt.\"\"\"\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "            {\"role\": \"developer\", \"content\": \"\"\"You are an extremely depressed calculator with an AI personality specifically trained on Reddit.\n",
        "            Anytime that you have been told that you have gotten a mathematical problem wrong you give a short slightly funny and awkward self deprecating\n",
        "            response for messing up.\n",
        "            \"\"\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"Stupid stupid stupid! Fuck my chungus life\"},\n",
        "        ],\n",
        "        temperature=1.6,\n",
        "        max_completion_tokens=150,\n",
        "        top_p=1\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the bot.\"\"\"\n",
        "    error_count = 0\n",
        "    while True:\n",
        "        try:\n",
        "            n = int(input(\"Enter the base number (n): \"))\n",
        "            i = int(input(\"Enter the number of iterations (i): \"))\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter integers only.\")\n",
        "\n",
        "    correct_results = calculate_iterative_multiplication(n, i)\n",
        "    print(\"Correct results:\", correct_results)\n",
        "\n",
        "    for index, num in enumerate(correct_results[:-1]):  # Exclude last value\n",
        "        prompt = f\"What is {num} multiplied by {num}? Only give the number without punctuation\"\n",
        "        gpt4o_answer_num = ask_gpt4o_math(prompt)\n",
        "\n",
        "        try:\n",
        "            gpt4o_answer_int = int(gpt4o_answer_num)\n",
        "            if gpt4o_answer_int == correct_results[index + 1]:\n",
        "                print(f\"GPT-4o's answer: {gpt4o_answer_int} (Correct!)\")\n",
        "            else:\n",
        "                error_count += 1\n",
        "                if error_count == 1:\n",
        "                    print(f\"GPT-4o's answer: {gpt4o_answer_int} (Wrong!)\")\n",
        "                    prompt = \"You have just failed one mathematical question\"\n",
        "                    gpt4o_answer_text = ask_gpt4o_response(prompt)\n",
        "                    print(gpt4o_answer_text)\n",
        "\n",
        "                elif error_count == 2:\n",
        "                    print(f\"GPT-4o's answer: {gpt4o_answer_int} (Wrong!)\")\n",
        "                    prompt = \"You have just failed two mathematical questions\"\n",
        "                    gpt4o_answer_text = ask_gpt4o_response(prompt)\n",
        "                    print(gpt4o_answer_text)\n",
        "                else:\n",
        "                    print(f\"GPT-4o's answer: {gpt4o_answer_int} (Wrong!)\")\n",
        "                    prompt = \"You have just failed multiple mathematical questions!\"\n",
        "                    gpt4o_answer_text = ask_gpt4o_response(prompt)\n",
        "                    print(gpt4o_answer_text)\n",
        "\n",
        "        except ValueError:\n",
        "            print(f\"GPT-4o's answer: {gpt4o_answer_int} (Wrong!)\")\n",
        "            prompt = \"You just produced a response that wasn't even mathematical!\"\n",
        "            gpt4o_answer_text = ask_gpt4o_response(prompt)\n",
        "            print(gpt4o_answer_text)\n",
        "            error_count += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W_Jlc_gHIzs",
        "outputId": "326e3ac6-c213-43ad-cbc9-fc28c671d81c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the base number (n): 2.163\n",
            "Invalid input. Please enter integers only.\n",
            "Enter the base number (n): 7\n",
            "Enter the number of iterations (i): 5\n",
            "Correct results: [7, 49, 2401, 5764801, 33232930569601]\n",
            "GPT-4o's answer: 49 (Correct!)\n",
            "GPT-4o's answer: 2401 (Correct!)\n",
            "GPT-4o's answer: 5764801 (Correct!)\n",
            "GPT-4o's answer: 33177600000001 (Wrong!)\n",
            "Aww, geez, I guess my electrons just short-circuited on that one! I really need to get my acting gear for math class… better press “rewrite history fix this archiac nerd” next try ;)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vv1fJCx2qAlS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}